{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pretrained Resnet50.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1WP4yjTZJDiEC9jHbZ7YswlrqX7_GhKrt",
      "authorship_tag": "ABX9TyMXzx8bwLjpARYpml40JxIw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xyzkpsf/CS-W182-CV-Project/blob/main/Pretrained_Resnet50.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HMQojtDGlhe5"
      },
      "source": [
        "try:\r\n",
        "    import torchbearer\r\n",
        "except:\r\n",
        "    !pip install -q torchbearer\r\n",
        "    import torchbearer\r\n",
        "\r\n",
        "!pip install livelossplot\r\n",
        "print(torchbearer.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9RbRisbfZhB"
      },
      "source": [
        "data_dir = '/content/drive/MyDrive/Spring 2021/CS 182/tiny-imagenet-200.zip'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NtnDnVwhkR14"
      },
      "source": [
        "!unzip '/content/drive/MyDrive/Spring 2021/CS 182/tiny-imagenet-200.zip'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nBe9EVp0kuqe"
      },
      "source": [
        "data_dir = '/content/tiny-imagenet-200'"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_UJ50pIDhV04"
      },
      "source": [
        "import torch, torchvision\r\n",
        "import torch.nn as nn\r\n",
        "import torch.optim as optim\r\n",
        "from torch.optim import lr_scheduler\r\n",
        "import torchvision.datasets as datasets\r\n",
        "import torch.utils.data as data\r\n",
        "import torchvision.transforms as transforms\r\n",
        "from torch.autograd import Variable\r\n",
        "import torchvision.models as models\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import time, os, copy, numpy as np\r\n",
        "from livelossplot import PlotLosses\r\n",
        "import sys\r\n",
        "#from train_model import train_model\r\n",
        "%matplotlib inline"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gg6nzzsbmmCB"
      },
      "source": [
        "data_transforms = {\r\n",
        "    'train': transforms.Compose([\r\n",
        "        transforms.RandomHorizontalFlip(),\r\n",
        "        transforms.ToTensor(),\r\n",
        "    ]),\r\n",
        "    'val': transforms.Compose([\r\n",
        "        transforms.ToTensor(),\r\n",
        "    ]),\r\n",
        "}\r\n",
        "\r\n",
        "data_dir = '/content/tiny-imagenet-200'\r\n",
        "\r\n",
        "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\r\n",
        "                                          data_transforms[x])\r\n",
        "                  for x in ['train', 'val']}\r\n",
        "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=128,\r\n",
        "                                             shuffle=True, num_workers=2)\r\n",
        "              for x in ['train', 'val']}\r\n",
        "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bALbd6yfABHJ"
      },
      "source": [
        "\r\n",
        "\r\n",
        "def train_model(model, dataloaders, dataset_sizes, criterion, optimizer, scheduler, num_epochs=25):\r\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\r\n",
        "    since = time.time()\r\n",
        "    liveloss = PlotLosses()\r\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\r\n",
        "    best_acc = 0.0\r\n",
        "\r\n",
        "    for epoch in range(num_epochs):\r\n",
        "        print('Epoch {}/{}'.format(epoch+1, num_epochs))\r\n",
        "        print('-' * 10)\r\n",
        "\r\n",
        "        # Each epoch has a training and validation phase\r\n",
        "        for phase in ['train', 'val']:\r\n",
        "            if phase == 'train':\r\n",
        "                scheduler.step()\r\n",
        "                model.train()  # Set model to training mode\r\n",
        "            else:\r\n",
        "                model.eval()   # Set model to evaluate mode\r\n",
        "\r\n",
        "            running_loss = 0.0\r\n",
        "            running_corrects = 0\r\n",
        "\r\n",
        "            # Iterate over data.\r\n",
        "            for i,(inputs, labels) in enumerate(dataloaders[phase]):\r\n",
        "                inputs = inputs.to(device)\r\n",
        "                labels = labels.to(device)\r\n",
        "\r\n",
        "                # zero the parameter gradients\r\n",
        "                optimizer.zero_grad()\r\n",
        "\r\n",
        "                # forward\r\n",
        "                # track history if only in train\r\n",
        "                with torch.set_grad_enabled(phase == 'train'):\r\n",
        "                    outputs = model(inputs)\r\n",
        "                    _, preds = torch.max(outputs, 1)\r\n",
        "                    loss = criterion(outputs, labels)\r\n",
        "\r\n",
        "                    # backward + optimize only if in training phase\r\n",
        "                    if phase == 'train':\r\n",
        "                        loss.backward()\r\n",
        "                        optimizer.step()\r\n",
        "\r\n",
        "                # statistics\r\n",
        "                running_loss += loss.item() * inputs.size(0)\r\n",
        "                running_corrects += torch.sum(preds == labels.data)\r\n",
        "                print(\"\\rIteration: {}/{}, Loss: {}.\".format(i+1, len(dataloaders[phase]), loss.item() * inputs.size(0)), end=\"\")\r\n",
        "\r\n",
        "#                 print( (i+1)*100. / len(dataloaders[phase]), \"% Complete\" )\r\n",
        "                sys.stdout.flush()\r\n",
        "                \r\n",
        "                \r\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\r\n",
        "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\r\n",
        "            if phase == 'train':\r\n",
        "                avg_loss = epoch_loss\r\n",
        "                t_acc = epoch_acc\r\n",
        "            else:\r\n",
        "                val_loss = epoch_loss\r\n",
        "                val_acc = epoch_acc\r\n",
        "            \r\n",
        "#             print('{} Loss: {:.4f} Acc: {:.4f}'.format(\r\n",
        "#                 phase, epoch_loss, epoch_acc))\r\n",
        "\r\n",
        "            # deep copy the model\r\n",
        "            if phase == 'val' and epoch_acc > best_acc:\r\n",
        "                best_acc = epoch_acc\r\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\r\n",
        "                \r\n",
        "        liveloss.update({\r\n",
        "            'log loss': avg_loss,\r\n",
        "            'val_log loss': val_loss,\r\n",
        "            'accuracy': t_acc,\r\n",
        "            'val_accuracy': val_acc\r\n",
        "        })\r\n",
        "                \r\n",
        "        liveloss.draw()\r\n",
        "        print('Train Loss: {:.4f} Acc: {:.4f}'.format(avg_loss, t_acc))\r\n",
        "        print(  'Val Loss: {:.4f} Acc: {:.4f}'.format(val_loss, val_acc))\r\n",
        "        print('Best Val Accuracy: {}'.format(best_acc))\r\n",
        "        print()\r\n",
        "    \r\n",
        "    time_elapsed = time.time() - since\r\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(\r\n",
        "        time_elapsed // 60, time_elapsed % 60))\r\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\r\n",
        "\r\n",
        "    # load best model weights\r\n",
        "    model.load_state_dict(best_model_wts)\r\n",
        "    return model\r\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ntJpNHtnUzE"
      },
      "source": [
        "model_ft = models.resnet50(pretrained=True)\r\n",
        "#Finetune Final few layers to adjust for tiny imagenet input\r\n",
        "model_ft.avgpool = nn.AdaptiveAvgPool2d(1)\r\n",
        "num_ftrs = model_ft.fc.in_features\r\n",
        "model_ft.fc = nn.Linear(num_ftrs, 200)\r\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\r\n",
        "model_ft = model_ft.to(device)\r\n",
        "#Multi GPU\r\n",
        "#model_ft = torch.nn.DataParallel(model_ft, device_ids=[0, 1])\r\n",
        "\r\n",
        "#Loss Function\r\n",
        "criterion = nn.CrossEntropyLoss()\r\n",
        "\r\n",
        "# Observe that all parameters are being optimized\r\n",
        "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\r\n",
        "\r\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\r\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\r\n",
        "\r\n"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LlX3_exQnbh8"
      },
      "source": [
        "model_ft = train_model(model_ft, dataloaders, dataset_sizes, criterion, optimizer_ft, exp_lr_scheduler,\r\n",
        "                       num_epochs=25)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6FASYq5CANCL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}