{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Simple Add CV_Ensemble .ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1n-MXu2fJzxqDu_AQGg3Dm1OVUYdXqMBD",
      "authorship_tag": "ABX9TyNCBAxMIdjWK0/inNIeyfLO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xyzkpsf/CS-W182-CV-Project/blob/main/Simple_Add_CV_Ensemble_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W76R8DyFgAfN"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import torchvision\n",
        "import pandas as pd\n",
        "from torchvision import datasets, models, transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim import lr_scheduler\n",
        "from torchvision.io import read_image\n",
        "from skimage import io, transform\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import copy\n",
        "import os\n",
        "import sys"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQxbsEQRgHGj"
      },
      "source": [
        "!unzip '/content/drive/MyDrive/Spring 2021/CS 182/tiny-imagenet-200.zip'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vnJkIyEvJFzg"
      },
      "source": [
        "class CustomImageDataset(Dataset):\n",
        "    def __init__(self, val_label_dir, img_dir, train_path, transform=None, target_transform=None):\n",
        "        super(CustomImageDataset, self).__init__()\n",
        "        self.val_label_file = pd.read_csv(val_label_dir, delimiter = \"\\t\", names=[\"pics\", \"labels\", \"_1\", \"_2\", \"_3\", \"_4\"])\n",
        "        self.img_labels = self.val_label_file[[\"pics\", 'labels']]\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "        self.classes, self.class_to_idx = self._find_classes(train_path)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_labels)\n",
        "\n",
        "    def _find_classes(self, dir):\n",
        "        \"\"\"\n",
        "        Finds the class folders in a dataset.\n",
        "        Args:\n",
        "            dir (string): Root directory path.\n",
        "        Returns:\n",
        "            tuple: (classes, class_to_idx) where classes are relative to (dir), and class_to_idx is a dictionary.\n",
        "        Ensures:\n",
        "            No class is a subdirectory of another.\n",
        "        \"\"\"\n",
        "        if sys.version_info >= (3, 5):\n",
        "            # Faster and available in Python 3.5 and above\n",
        "            classes = [d.name for d in os.scandir(dir) if d.is_dir()]\n",
        "        else:\n",
        "            classes = [d for d in os.listdir(dir) if os.path.isdir(os.path.join(dir, d))]\n",
        "        classes.sort()\n",
        "        class_to_idx = {classes[i]: i for i in range(len(classes))}\n",
        "        return classes, class_to_idx\n",
        "\n",
        "    def pad(self, img):\n",
        "        padding = np.ones((64, 64, 2))\n",
        "        img = img.reshape((64, 64, 1))\n",
        "        img = np.concatenate((img, padding), axis=2)\n",
        "        return img.astype(np.float32)\n",
        "      \n",
        "    def __getitem__(self, idx):\n",
        "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
        "        img = Image.open(img_path)\n",
        "        img = copy.deepcopy(np.asarray(img))\n",
        "        # if it has less than 3 channels\n",
        "        if img.shape != (64, 64, 3):\n",
        "            img = self.pad(img)\n",
        "        #print(img.shape)\n",
        "        label = self.img_labels.iloc[idx, 1]\n",
        "        label = self.class_to_idx[label]\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        #sample = {\"image\": img, \"label\": label}\n",
        "        return img, label"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12uDWdL4gNlD"
      },
      "source": [
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        #transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        #transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}\n",
        "\n",
        "data_dir = '/content/tiny-imagenet-200'\n",
        "\n",
        "val_label_dir = '/content/tiny-imagenet-200/val/val_annotations.txt'\n",
        "\n",
        "image_datasets = {}\n",
        "\n",
        "image_datasets['train'] = datasets.ImageFolder(os.path.join(data_dir, 'train'),\n",
        "                                          data_transforms['train'])\n",
        "\n",
        "image_datasets['val'] = CustomImageDataset(val_label_dir, data_dir+'/val/images', \n",
        "                                           os.path.join(data_dir, 'train'),\n",
        "                                           transform=data_transforms['val'])\n",
        "\n",
        "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=128,\n",
        "                                             shuffle=True, num_workers=2)\n",
        "                                            for x in ['train', 'val']}\n",
        "\n",
        "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "llxIgvXAgi2a"
      },
      "source": [
        "# No pretrained parameters\n",
        "\n",
        "\n",
        "# First model\n",
        "model1 = models.resnet18(pretrained=False)\n",
        "model1.avgpool = nn.AdaptiveAvgPool2d(1)\n",
        "num_ftrs = model1.fc.in_features\n",
        "model1.fc = nn.Linear(num_ftrs, 200)\n",
        "model1.conv1 = nn.Conv2d(3,64, kernel_size=(3,3), stride=(1,1), padding=(1,1))\n",
        "model1.maxpool = nn.Sequential()\n",
        "model1 = model1.to(device)\n",
        "\n",
        "\n",
        "# Second model\n",
        "model2 = models.resnet50(pretrained=False)\n",
        "model2.avgpool = nn.AdaptiveAvgPool2d(1)\n",
        "num_ftrs = model2.fc.in_features\n",
        "model2.fc = nn.Linear(num_ftrs, 200)\n",
        "model2.conv1 = nn.Conv2d(3,64, kernel_size=(3,3), stride=(1,1), padding=(1,1))\n",
        "model2.maxpool = nn.Sequential()\n",
        "model2 = model2.to(device)\n",
        "\n",
        "\n",
        "# Third model\n",
        "model3 = models.resnet101(pretrained=False)\n",
        "model3.avgpool = nn.AdaptiveAvgPool2d(1)\n",
        "num_ftrs = model3.fc.in_features\n",
        "model3.fc = nn.Linear(num_ftrs, 200)\n",
        "model3.conv1 = nn.Conv2d(3,64, kernel_size=(3,3), stride=(1,1), padding=(1,1))\n",
        "model3.maxpool = nn.Sequential()\n",
        "model3 = model3.to(device)\n",
        "\n",
        "\n",
        "#Multi GPU\n",
        "#model = torch.nn.DataParallel(model, device_ids=[0, 1])\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FcN3IbaPhJeT"
      },
      "source": [
        "# Don't REPLACE the old one.\n",
        "# Remeber to change the temp.pt each time.\n",
        "# model_save_path = \"/content/drive/MyDrive/CV Project Model State Dict/temp.pt\"\n",
        "# torch.save(model.state_dict(), model_save_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JuyldEw6WNkX"
      },
      "source": [
        "class MyEnsemble(nn.Module):\n",
        "    def __init__(self, model1, model2, model3):\n",
        "          super(MyEnsemble,self).__init__()\n",
        "          self.model1 = model1 \n",
        "          self.model2 = model2 \n",
        "          self.model3 = model3  \n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.model1(x.clone())\n",
        "        \n",
        "        x2 = self.model2(x.clone())\n",
        "           \n",
        "        x3 = self.model3(x)\n",
        "        \n",
        "        x = x1 + x2 + x3\n",
        "\n",
        "        return x"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YlU_BeNOZjhj"
      },
      "source": [
        "def validation(model, dataloaders, criterion):\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for i,(inputs, labels) in enumerate(dataloaders['val']):\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (preds == labels).sum().item()\n",
        "            if i % 10 == 0:\n",
        "                print('\\rIteration: {}/{}, Avg Acc: {:.4f}'.format(i+1, len(dataloaders['val']), (100 * correct / total)))\n",
        "    print(\"Total Sample numbers: {}, Overall Acc: {:.2f}\".format(total, (100 * correct / total)))\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6agcG7qPXgSU"
      },
      "source": [
        "\n",
        "PATH1 = \"/content/drive/MyDrive/CV Project Model State Dict/ResNet18 10-Epoch.pt\"\n",
        "model1.load_state_dict(torch.load(PATH1))\n",
        "for param in model1.parameters():\n",
        "    param.requires_grad_(False)\n",
        "\n",
        "\n",
        "PATH2 = \"/content/drive/MyDrive/CV Project Model State Dict/ResNet50 5-Epoch.pt\"\n",
        "model2.load_state_dict(torch.load(PATH2))\n",
        "for param in model2.parameters():\n",
        "    param.requires_grad_(False)\n",
        "\n",
        "PATH3 = \"/content/drive/MyDrive/CV Project Model State Dict/ResNet101.pt\"\n",
        "model3.load_state_dict(torch.load(PATH3))\n",
        "for param in model3.parameters():\n",
        "    param.requires_grad_(False)\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3oi3AgmYNgx-"
      },
      "source": [
        "\n",
        "# Only finish training model1 so far\n",
        "model = MyEnsemble(model1, model2, model3)\n",
        "model = model.to(device)\n",
        "#validation(model, dataloaders, nn.CrossEntropyLoss())"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-5R4BtK8KOQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ee8024d-0223-4109-f672-461f45bf1a05"
      },
      "source": [
        "validation(model, dataloaders, nn.CrossEntropyLoss())"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration: 1/79, Avg Acc: 47.6562\n",
            "Iteration: 11/79, Avg Acc: 46.4489\n",
            "Iteration: 21/79, Avg Acc: 45.4613\n",
            "Iteration: 31/79, Avg Acc: 46.2198\n",
            "Iteration: 41/79, Avg Acc: 44.4360\n",
            "Iteration: 51/79, Avg Acc: 45.8180\n",
            "Iteration: 61/79, Avg Acc: 46.7085\n",
            "Iteration: 71/79, Avg Acc: 47.1831\n",
            "Total Sample numbers: 10000, Overall Acc: 47.40\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}